{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "k_5UhNA8gI5N"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Conv2D, Reshape\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NL2JkcK0gQaR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-05 13:50:11--  http://repo.gorchilov.net/datasets/genetics.tar.gz\n",
      "Resolving repo.gorchilov.net (repo.gorchilov.net)... 185.97.75.52\n",
      "Connecting to repo.gorchilov.net (repo.gorchilov.net)|185.97.75.52|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 63942414 (61M) [application/octet-stream]\n",
      "Saving to: ‘/tmp/genetics.tar.gz’\n",
      "\n",
      "/tmp/genetics.tar.g 100%[===================>]  60.98M  11.1MB/s    in 5.6s    \n",
      "\n",
      "2020-12-05 13:50:17 (10.9 MB/s) - ‘/tmp/genetics.tar.gz’ saved [63942414/63942414]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget repo.gorchilov.net/datasets/genetics.tar.gz -O /tmp/genetics.tar.gz\n",
    "!tar -xf /tmp/genetics.tar.gz -C /tmp\n",
    "\n",
    "import h5py\n",
    "\n",
    "train = h5py.File('/tmp/train.h5', mode='r')\n",
    "train_X = train['data'][:]\n",
    "train_y = train['labels'][:]\n",
    "\n",
    "test = h5py.File('/tmp/test.h5', mode='r')\n",
    "test_X = test['data'][:]\n",
    "test_y = test['labels'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-RO8XQ9WY0J"
   },
   "source": [
    "non_one_hot = np.array([argmax(x, axis=0).numpy() for x in train_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NhQcCHZ77hA4"
   },
   "outputs": [],
   "source": [
    "expanded = np.expand_dims(train_X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38115,
     "status": "ok",
     "timestamp": 1606676530892,
     "user": {
      "displayName": "Victor Gorchilov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhVOO2f8bSU9D2WCOuhm9D6m40pljIpR5gmOLVhCA=s64",
      "userId": "15273504440532916403"
     },
     "user_tz": -120
    },
    "id": "GXqXKCCN7u_s",
    "outputId": "5f63366d-5bb8-421b-8065-e02e19a50db8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4, 1000, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "CDZonLvgUg2R"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "                    Conv2D(4, kernel_size=(4, 4), activation='relu', input_shape=(4, 1000, 1)),\n",
    "                    Reshape((997, 4)),\n",
    "                    Bidirectional(LSTM(64)),\n",
    "                    Dense(512, activation='relu'),\n",
    "                    Dense(256, activation='relu'),\n",
    "                    Dense(128, activation='relu'),\n",
    "                    Dense(1, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1606676722977,
     "user": {
      "displayName": "Victor Gorchilov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhVOO2f8bSU9D2WCOuhm9D6m40pljIpR5gmOLVhCA=s64",
      "userId": "15273504440532916403"
     },
     "user_tz": -120
    },
    "id": "foPUfgnJ7Fe5",
    "outputId": "252c4c1f-bf21-4bf1-e3b2-da81706f3e07"
   },
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-18cJKWvVagq"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8184059,
     "status": "ok",
     "timestamp": 1606688892036,
     "user": {
      "displayName": "Victor Gorchilov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhVOO2f8bSU9D2WCOuhm9D6m40pljIpR5gmOLVhCA=s64",
      "userId": "15273504440532916403"
     },
     "user_tz": -120
    },
    "id": "l7zuT5LpXDKx",
    "outputId": "95109dee-e554-4c6c-8e8c-9d5bfd6939bd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 14547271.0000\n",
      "Epoch 2/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 14188624.0000\n",
      "Epoch 3/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 14173685.0000\n",
      "Epoch 4/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 14182396.0000\n",
      "Epoch 5/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14182665.0000\n",
      "Epoch 6/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 14152539.0000\n",
      "Epoch 7/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14174750.0000\n",
      "Epoch 8/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14160950.0000\n",
      "Epoch 9/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14159036.0000\n",
      "Epoch 10/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14165882.0000\n",
      "Epoch 11/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14144375.0000\n",
      "Epoch 12/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14169041.0000\n",
      "Epoch 13/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14126609.0000\n",
      "Epoch 14/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14166185.0000\n",
      "Epoch 15/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14147878.0000\n",
      "Epoch 16/2000\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 14123447.0000\n",
      "Epoch 17/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14131996.0000\n",
      "Epoch 18/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14149459.0000\n",
      "Epoch 19/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14109462.0000\n",
      "Epoch 20/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14099241.0000\n",
      "Epoch 21/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14069802.0000\n",
      "Epoch 22/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14100423.0000\n",
      "Epoch 23/2000\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 14093343.0000\n",
      "Epoch 24/2000\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 14095332.0000\n",
      "Epoch 25/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14077409.0000\n",
      "Epoch 26/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14043781.0000\n",
      "Epoch 27/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14034742.0000\n",
      "Epoch 28/2000\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 14030145.0000\n",
      "Epoch 29/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14022384.0000\n",
      "Epoch 30/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14027723.0000\n",
      "Epoch 31/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14026629.0000\n",
      "Epoch 32/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14004762.0000\n",
      "Epoch 33/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 13965413.0000\n",
      "Epoch 34/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 14012518.0000\n",
      "Epoch 35/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 13960666.0000\n",
      "Epoch 36/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 13998799.0000\n",
      "Epoch 37/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 14001300.0000\n",
      "Epoch 38/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 13977421.0000\n",
      "Epoch 39/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 13926481.0000\n",
      "Epoch 40/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 13963358.0000\n",
      "Epoch 41/2000\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 13930509.0000\n",
      "Epoch 42/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 13941962.0000\n",
      "Epoch 43/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 13934992.0000\n",
      "Epoch 44/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13919761.0000\n",
      "Epoch 45/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13962777.0000\n",
      "Epoch 46/2000\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 13913078.0000\n",
      "Epoch 47/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13929205.0000\n",
      "Epoch 48/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13903231.0000\n",
      "Epoch 49/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13864081.0000\n",
      "Epoch 50/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13860571.0000\n",
      "Epoch 51/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13899833.0000\n",
      "Epoch 52/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 13859952.0000\n",
      "Epoch 53/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 13866570.0000\n",
      "Epoch 54/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13855406.0000\n",
      "Epoch 55/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13810314.0000\n",
      "Epoch 56/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13808508.0000\n",
      "Epoch 57/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13810588.0000\n",
      "Epoch 58/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13795321.0000\n",
      "Epoch 59/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13766043.0000\n",
      "Epoch 60/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13779049.0000\n",
      "Epoch 61/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 13719211.0000\n",
      "Epoch 62/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 13738521.0000\n",
      "Epoch 63/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 13550071.0000\n",
      "Epoch 64/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 13595960.0000\n",
      "Epoch 65/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 13572039.0000\n",
      "Epoch 66/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 13452166.0000\n",
      "Epoch 67/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 13430437.0000\n",
      "Epoch 68/2000\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 13389768.0000\n",
      "Epoch 69/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 13357777.0000\n",
      "Epoch 70/2000\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 13294303.0000\n",
      "Epoch 71/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 13187759.0000\n",
      "Epoch 72/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 13079878.0000\n",
      "Epoch 73/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 13063908.0000\n",
      "Epoch 74/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 13000033.0000\n",
      "Epoch 75/2000\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 12879184.0000\n",
      "Epoch 76/2000\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 12697624.0000\n",
      "Epoch 77/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 12629421.0000\n",
      "Epoch 78/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 12479204.0000\n",
      "Epoch 79/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 12378880.0000\n",
      "Epoch 80/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 12094139.0000\n",
      "Epoch 81/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 11987798.0000\n",
      "Epoch 82/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 11827360.0000\n",
      "Epoch 83/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 11557349.0000\n",
      "Epoch 84/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 11019694.0000\n",
      "Epoch 85/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 11067205.0000\n",
      "Epoch 86/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 10786294.0000\n",
      "Epoch 87/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 10521633.0000\n",
      "Epoch 88/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 10346311.0000\n",
      "Epoch 89/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 9657248.0000\n",
      "Epoch 90/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 9712676.0000\n",
      "Epoch 91/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 9310722.0000\n",
      "Epoch 92/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 9046568.0000\n",
      "Epoch 93/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 8872818.0000\n",
      "Epoch 94/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 8557687.0000\n",
      "Epoch 95/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 8332441.5000\n",
      "Epoch 96/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 8009601.0000\n",
      "Epoch 97/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 7653207.0000\n",
      "Epoch 98/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 7879046.5000\n",
      "Epoch 99/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 7511138.0000\n",
      "Epoch 100/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 7048222.0000\n",
      "Epoch 101/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 6866947.5000\n",
      "Epoch 102/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 6621326.0000\n",
      "Epoch 103/2000\n",
      "63/63 [==============================] - 3s 56ms/step - loss: 6546871.0000\n",
      "Epoch 104/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 6377450.0000\n",
      "Epoch 105/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 6378461.0000\n",
      "Epoch 106/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 6287496.0000\n",
      "Epoch 107/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 6269955.0000\n",
      "Epoch 108/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 5926763.5000\n",
      "Epoch 109/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 5693581.5000\n",
      "Epoch 110/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 5732061.0000\n",
      "Epoch 111/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 5257918.0000\n",
      "Epoch 112/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 5378875.0000\n",
      "Epoch 113/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 5257880.5000\n",
      "Epoch 114/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 4864787.5000\n",
      "Epoch 115/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 4941387.5000\n",
      "Epoch 116/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 4849540.0000\n",
      "Epoch 117/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 4806999.5000\n",
      "Epoch 118/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 4570441.5000\n",
      "Epoch 119/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 4633187.5000\n",
      "Epoch 120/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 4485631.0000\n",
      "Epoch 121/2000\n",
      "63/63 [==============================] - 4s 57ms/step - loss: 4531251.0000\n",
      "Epoch 122/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 4206085.5000\n",
      "Epoch 123/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 4114268.2500\n",
      "Epoch 124/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 4034703.0000\n",
      "Epoch 125/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 3710477.7500\n",
      "Epoch 126/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 3620303.7500\n",
      "Epoch 127/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 3553963.7500\n",
      "Epoch 128/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 3467256.0000\n",
      "Epoch 129/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 3422950.7500\n",
      "Epoch 130/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 3103197.7500\n",
      "Epoch 131/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 2886826.5000\n",
      "Epoch 132/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 2798708.2500\n",
      "Epoch 133/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 2804004.2500\n",
      "Epoch 134/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 2458637.7500\n",
      "Epoch 135/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 2336786.5000\n",
      "Epoch 136/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 2118249.5000\n",
      "Epoch 137/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 2050520.5000\n",
      "Epoch 138/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 1812266.3750\n",
      "Epoch 139/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 1689747.1250\n",
      "Epoch 140/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 1597726.1250\n",
      "Epoch 141/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 1399961.0000\n",
      "Epoch 142/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 1270494.0000\n",
      "Epoch 143/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 1304624.6250\n",
      "Epoch 144/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 1116085.2500\n",
      "Epoch 145/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 1083090.2500\n",
      "Epoch 146/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 1063352.7500\n",
      "Epoch 147/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 1041806.1875\n",
      "Epoch 148/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 981222.5000\n",
      "Epoch 149/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 1000948.0625\n",
      "Epoch 150/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 937068.4375\n",
      "Epoch 151/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 958128.7500\n",
      "Epoch 152/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 967455.0625\n",
      "Epoch 153/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 832689.6250\n",
      "Epoch 154/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 889046.6250\n",
      "Epoch 155/2000\n",
      "63/63 [==============================] - 4s 58ms/step - loss: 766781.8750\n",
      "Epoch 156/2000\n",
      "63/63 [==============================] - 4s 56ms/step - loss: 919524.0625\n",
      "Epoch 157/2000\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 860218.3125\n",
      "Epoch 158/2000\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 758024.3125\n",
      "Epoch 159/2000\n",
      "26/63 [===========>..................] - ETA: 1s - loss: 736319.3125"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "\n",
    "history = model.fit(expanded[:10000],\n",
    "                    train_y[:10000],\n",
    "                    epochs=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1021,
     "status": "ok",
     "timestamp": 1606689964026,
     "user": {
      "displayName": "Victor Gorchilov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhVOO2f8bSU9D2WCOuhm9D6m40pljIpR5gmOLVhCA=s64",
      "userId": "15273504440532916403"
     },
     "user_tz": -120
    },
    "id": "XGGYqaJMRcOw",
    "outputId": "78fcf24a-ac8f-423d-a1e5-906072fca40b"
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 3000\n",
    "\n",
    "plt.title('all epochs')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(range(start, end), history.history['loss'][start:end])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2481,
     "status": "ok",
     "timestamp": 1606689317747,
     "user": {
      "displayName": "Victor Gorchilov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhVOO2f8bSU9D2WCOuhm9D6m40pljIpR5gmOLVhCA=s64",
      "userId": "15273504440532916403"
     },
     "user_tz": -120
    },
    "id": "IBqMj3q7Z6Xn",
    "outputId": "2f365389-c509-4ed6-a4ba-3579d45a1b09"
   },
   "outputs": [],
   "source": [
    "model.evaluate(np.expand_dims(test_X, axis=-1)[:10000], test_y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2563,
     "status": "ok",
     "timestamp": 1606689580464,
     "user": {
      "displayName": "Victor Gorchilov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhVOO2f8bSU9D2WCOuhm9D6m40pljIpR5gmOLVhCA=s64",
      "userId": "15273504440532916403"
     },
     "user_tz": -120
    },
    "id": "uFi4hl1_P4Kg",
    "outputId": "583da3c9-fa6e-4be9-ee31-8edaa46d79d2"
   },
   "outputs": [],
   "source": [
    "model.evaluate(expanded[:10000], train_y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qU3SbEKlKVtw"
   },
   "outputs": [],
   "source": [
    "model.save('model')\n",
    "\n",
    "!tar -zcvf model.tar.gz model\n",
    "\n",
    "# from google.colab import files\n",
    "# files.download('model.tar.gz') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP0pFHj/YAGW6bBoAlrWhex",
   "collapsed_sections": [],
   "name": "conv-lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
